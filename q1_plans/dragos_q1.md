# Crossover Q1 Plan & Q4 Results

The plan has three parts, in three separate tabs:

- Hiring Services (the key focus)
- WorkSmart
- BrainLift Coach

The overall budget structure is in a separate tab: Budget Breakdown

---

## Tab 1: Hiring Services

### Q4'25

#### **Hiring**

- The **average time to fill is ~5 weeks**, with SVP or up positions in EDU standing out at >20 weeks.
- In terms of open orders, out of **161 open orders, 31 are from Q3 (25 EDU), while 15 are older than that**.
- The **common challenges** in filling positions are a mix of
  - **Hyper-targeted requirements**, specifically for the most senior or niche roles (hard to source).
    - In Q4, we have set up an outbound recruiter service, working with specialized well-connected recruiters to source talent for positions that require a very specific past employer or experience. Impact TBD by EoQ4.
  - **SME RWA/interview grading backlogs**
    - AI grading is taking most of the RWA grading load, but some time initial investment from SMEs will always be required. Calibrating RWAs with the current team is incredibly helpful in increasing filter quality and reducing time to hire, but something most HMs are not willing to do.
  - **Evolving hiring requirements**

**Time to fill & Open order age data:**

| Time to fill (weeks) |          |      |     |             |     | Open order age (weeks) |          |      |     |             |
| :------------------- | :------- | ---- | --- | ----------- | :-- | :--------------------- | :------- | ---- | --- | ----------- |
|                      |          | _BU_ |     |             |     |                        |          | _BU_ |     |             |
| _Rate bucket_        | _Values_ | EDU  | SW  | Grand Total |     | _Rate bucket_          | _Values_ | EDU  | SW  | Grand Total |
| a. Under 50          | Orders   | 39   | 23  | 62          |     | a. Under 50            | Orders   | 54   | 29  | 83          |
|                      | Median   | 5    | 4   | 5           |     |                        | Median   | 8    | 4   | 6           |
|                      | Avg      | 6    | 4   | 6           |     |                        | Avg      | 8    | 6   | 7           |
| b. VP-rate roles     | Orders   | 30   | 1   | 31          |     | b. VP-rate roles       | Orders   | 66   | 3   | 69          |
|                      | Median   | 5    | 4   | 4           |     |                        | Median   | 7    | 8   | 7           |
|                      | Avg      | 7    | 4   | 7           |     |                        | Avg      | 7    | 12  | 7           |
| c. SVP or higher     | Orders   | 3    | 2   | 5           |     | c. SVP or higher       | Orders   | 8    | 1   | 9           |
|                      | Median   | 22   | 5   | 8           |     |                        | Median   | 11   | 12  | 12          |
|                      | Avg      | 26   | 5   | 17          |     |                        | Avg      | 16   | 12  | 16          |

#### **Retention**

- On the year, our **90-day retention is 85%** (up from 72% in 2024 and 67% in 2023)
- When you **limit the data to low performance and non-compliance** only (factoring out resignations, budget cuts, and short-term projects ending), our **90-day retention is 91%** (up from 74% in 2024 and 67% in 2023)
- **Resignations outnumbered terminations** - 120 vs 104 (excl. students/interns/non-ESW). Common resignation reasons:
  - Stress/burnout/lack of leadership
  - Culture mismatch/WorkSmart
  - Better offers elsewhere, especially India/Brazil/Nigeria/Turkey (clear signal of our decreasing competitiveness)
- **Termination feedback quality** remains an issue, one that we (will) partially solve in Q4 and will continue to work on.
  - This is not bad will, but a lack of understanding of the benefits of actionable feedback in improving hiring.

#### **Brand/values impact insights**

We implemented a survey in the candidate portal, randomly serving one 'branding impact' question at specific moments in the journey. We've received >7.5K responses to date, enabling the deepest data-driven insights XO has ever had. Findings:

- The biggest issue is that most **candidates don't even see our brand content**: <50% are not aware of our LinkedIn community or newsletter, even more have never seen a testimonial
  - Those who see our content, found it useful and motivated them to invest time in their job application.
- **<50% of education candidates believe XO is a great place to find a job in Ed Tech**. In contrast, >70% of remote work tech-job applicants believe that Crossover is a great place to find a remote job (our core positioning for years). The 'employer brand' for EDU needs investment and Crossover is committing to fill this gap, expecting to have an impact on hiring efficiency.
- **US in-person candidates have the lowest trust, the biggest culture concerns, lowest content visibility/awareness**, and least pay-motivated. Incidentally, they are also the most likely to report issues.
- Unexpectedly brand-focused surveys surfaced **technical issues and friction** with notable impact on completion rates.

#### **Q4 key platform, experience and brand improvements**

**Pipeline management improvements**

- **Improved AI grading** - agent based, now supporting video - increasing coverage of AI graded assessment. As this is rolled out, it will also lead to switch assessments from low-bar grading to full AI-grading.
- **Enabled AIPIs** that are now simplifying admin activities, enabling faster AI-based analysis. This is a recent addition and an important waypoint in our strategy of moving work to AI.
- Adjusted the application process to **match on-site education hiring** - as a platform designed for hiring for remote roles, it lacked key elements specific to on-site hiring that create extra work for both our teams and customer teams.
- **Updated the GenAI experience assessment** to have a higher bar and more modern inputs. We did this because Ignite and Central Eng felt the AI talent at the interview stage wasn't sufficient. 50% of candidates used to score 90%+. Now, 20% of candidates score 80%+. We feel much better about the quality of candidates who reach the interview stage.
- Added **proctoring for commonly used coding assessment**. We did this because Central Eng reported 80%+ of the candidates who reached the interview stage cheated on the assessment, so they weren't getting a good signal.
- **Rolled out AI-based "simulation"-like assessment** - ticket troubleshooting & resolution process for L2 Customer Engineer (aimed to eventually remove graduation interviews), admission work simulations, etc
- (Soon) **Collect rich termination feedback** - switch termination process to an AI-based conversation-like process that is loaded with candidate specific hiring context and the pipeline then and now requirements and can focus the conversation on collecting actionable feedback to improve pipeline and explain retention issues

**Hiring manager experience improvements**

- Rolled out our own **interview recording solution** (based on recall.ai, of-the-shelf platform) to solve our systemic issue of lacking insights from HM interviews. This solves the problem of non-uniform access to read.ai, users not setting up their recording to go to Crossover and other friction points.
- (Soon) **Improved Spotlight** - our AI-generated candidate executive summary aimed to reduce interview prep and time, and support HMs with interview planning. Prep materials and reminders to provide interview feedback follow users in their workspace with GChat notifications.

**Candidate experience improvements**

- **Switched emailing platform** from ancient tech to a modern, more capable solution - customer.io - this will enable Andrew in Q1 to drive a lot of improvements in candidate messaging, content personalization and help make visible our employer brand content

**Brand visibility improvements**

- **AI Discovery Engine Activated**: +103% AI Sessions: ChatGPT now drives 95% of AI traffic, proving the AI-first SEO pivot worked. This matters because AI search is becoming a parallel discovery channel - capturing high-intent terms like "remote jobs" and "remote education jobs." Next: Double down on long-form content and split Remote/EdTech audiences to strengthen AI recommendations.
- **Quality Over Volume: Non-Branded Traffic Now Dominates**. Shifted from brand-dependent to intent-led traffic - non-branded clicks now 55.6% of organic traffic while total sessions declined 8.5%. Blog quality improved significantly (CTR up to 0.79%, EEAT at 9.5). Why it matters: Less vanity traffic, more conversion-ready visitors finding us.

---

### Q1'26 Plan

The main theme of Q1 and 2026 is **supporting the growth of the education business**. The improvements will be systemic and many will naturally benefit the software business. The improvements will cover sourcing, vetting, retention and operational efficiency in the hiring team and service.

#### **Goals**

##### **Goal 1. Time-to-fill consistency while supporting Alpha expansion (10x growth in 2026)**

Hiring managers need simple and reliable answers on when to expect their hire(s). Our targets for time-to-offer are:

| Level | Crossover target (high CCAT) |                              |                                    | Staffing firms |
| :---- | ---------------------------- | ---------------------------- | ---------------------------------- | :------------: |
|       | Remote                       | Hyperlocal (specific cities) | Hypertargeted (specific employers) |                |
| IC    | 4 weeks                      | 4 weeks                      | 6 weeks                            |   4–8 weeks    |
| VP    | 5 weeks                      | 6 weeks                      | 10 weeks                           |  6–10+ weeks   |
| SVP   | 6 weeks                      | 10 weeks                     | 16 weeks                           |  12–18 weeks   |

##### **Goal 2. Maintain 90-days retention, improve 180-days retention**

The primary focus of Crossover is filling orders that pass a quality bar as defined by the R2, relying on the fact that high quality R2 will produce the great hires. Nonetheless, bad hires come at a high business cost and opportunity cost, so we are also actively monitoring and working to improve retention. Specifically:

- 90-day retention - the standard metric for all staffing firms. This is generally healthy, but has room for improvement
- 180-day retention - not necessarily a standard metric, but we monitor it to understand long term success of new hires and identify improvement opportunities both for our customers and for Crossover.

| Retention | Crossover (perf/compliance) | Crossover (overall, incl. budget) | High-Performing Firms (AI research based) |
| :-------- | :-------------------------: | :-------------------------------: | :---------------------------------------: |
| 90-days   |  Current: 91% Target: >90%  |     Current: 85% Target: N/A      |                  90–95%                   |
| 180-days  |  Current: 76% Target: 80%   |     Current: 62% Target: N/A      |                  75-85%                   |

**Facts:**

- 2025 assignment terminations big buckets
  - 33% of terminations were performance-related
  - 29% of the terminations in 2025 were voluntary resignations
  - 31% budget-related
  - 7% fraud
- Challenges: >30% of the termination feedback cannot be used in any way to improve the hiring process
- Opportunity: ~50% of the terminations (across all BUs/functions) included comments related to a lack of accountability or ownership pointing to an opportunity to improve both filtering and new hire onboarding

#### **Tactics**

**Improve operations**

- **Scale the hiring team:** Hire two great VP OrgBuilders and raise the bar of the service.
- **Continue moving work to AI:**
  - Continue coding practices into AIPIs or AI-enabled automations
  - Expose AIPIs to our customers - removing the need to "sync" with an OrgBuilder
  - Continue eliminating admin work - the results of performing an audit identified admin work around handling gaps in the interview process, coordinating onboarding with central support, supporting candidates on topics that are not covered or are incorrectly covered in the support portal.

**Improve sourcing**

- **Improve completion rates (primarily BFQ):** today, 35% of job applicants take the time to complete the BFQ. Technical issues are not the main problem, but perceived simplicity
- **Scale hypertargeted recruitment:**
  - **Improve sourcing efficiency for hyperlocal jobs** - smaller pools require for greater efficiency, for example but not limited to retargeting or drip campaigns
  - **Further improve outbound recruitment** - we believe that roles with specific requirements on past employers or education can be served well by classic outbound recruiting. While inbound recruitment has to work, these types of roles have historically been slower to fill. In Q4 we established an outbound recruitment service that produced a number of strong late stage candidates and in Q1 we plan to further improve it.
- **Explore Local/In-Person Recruiting Tactics:**
  - Leverage Alpha's in-person events (parent info sessions, open houses) as recruiting opportunities for hyperlocal roles as these already attract mission-aligned attendees who are prime candidates.
  - We will try three approaches:
    - **No staff — passive touchpoints only**. Test demand before investing in people. Use a branded "Join Our Mission" signage at the venue, a small display table with flyers and QR codes linking to a careers landing page. Alpha event staff doesn't need to do anything beyond pointing if asked. Low cost, low effort — but also low conversion. This is a toe-in-the-water approach to test interest.
    - **Local on-demand contractors** (Upwork). Hire and train someone already in each target city to attend 2-3 events per quarter. Flexible to scale up or down. The risk is quality variance - harder to find someone with executive presence needed for rooms full of high-net-worth parents.
    - **One dedicated person that flies in**. Highest cost and turnaround but consistent quality and messaging. They build expertise over time, becoming the single point of accountability. Downside: travel logistics, availability constraints, and single point of failure.
- **Post jobs on Alpha web properties** - Alpha is generating a lot of attention, including a lot of smart, mission-aligned people that want to be part of it. We want them applying for jobs instead of direct outreach.

**Improve brand and the image of a highlight desirable employer**

- **Leverage and reflect Alpha's brand as great employee branding for education roles**
  - **Position Crossover as a top source of edtech jobs -** >50% of job applicants applying to our edu jobs do not believe that Crossover is a great place for edtech jobs.
  - **Decouple the candidate experience for enterprise software-type roles vs education roles**: this will allow us to segment the candidate audiences, and convey the right message and values.
  - **Create high quality job seeker focused content** - create testimonials, stories and articles to reflect the mission and purpose driven culture in our education businesses
- **Improve brand and values visibility:**
  - Candidates who interact with our brand content love the content and find it motivating, but 50% of first time applicants do not get to see it. We will create touch points to improve position clarity, brand visibility and use this to convey our messaging on other key topics like lack of trust, culture, job security, or hiring process (these adding up to >70% of sources of concerns).

**Improve filtering**

- **Increase AI-grading coverage**: 77% of RWAs are already graded with AI. We are now adding video submission grading to streamline Guide pipelines (historically a significant bottleneck, moreover as there was no clarity on the rubric).
- **Plagiarism detection:** fraud/leaked answers as well as AI-generated submissions for non-AI assessments are a significant challenge for some pipelines. Solving this will remove the need to perform (subjective) filtering interviews and improve interview pass rates.
- **Improve domain-specific AI-based assessments approaches**: in Q4 we have piloted new AI-led scenario-based assessments for support and simulations-based assessments. Their benefits: closer to the real work and more fraud-resistant.

**Improve culture alignment & onboarding**

- **Filter for culture fit**: many edu termination call out on culture fit, misaligned values.
- **Filter for non-easily blockable**: ~50% BU terminations call out hires not following through, needing constant hand-holding, not escalating blockers, leaving work not done, not completing work independently. While this is tightly connected to the team managerial approach, we believe Crossover can improve filtering too by finding ways to assess what we have historically called "non-easily blockable" - a mix of autonomy, focus and resourcefulness.
- **Work with HMs to improve onboarding**: all the above have as a solution training during onboarding, with many cases being easily preventable by setting proper expectations and providing team-specific guidelines. We aim to:
  - Establish a quality bar for the training/onboarding material
  - Offer a simple AI bot that uses existing team materials, matches it to the QB and collects missing details
  - Turn that into "ramp-up" training documentation as well as culture alignment check during the hiring process

#### **Notable budget adjustments**

**New budget allocation:**

- Two new VP OrgBuilder hires: 100k
- Video production of edu-focused employer brand materials: $50k
- Outbound Recruitment for hyperlocal: 50k
- Hiring through Alpha local events: 70k
- Extra ad budget: $20k (PPC advertising supporting our goal to increase LinkedIn apply rate for on-site jobs)
- Increased Zamstars quarterly value by $17k to support planned improvements on website and emails, SEO, etc.

**Budget reduction:**

- Central Support charge dropped from $500k to $330k based on pricing changes (no significant changes in volume, no notable waste in support work)
- Renewing with LinkedIn means more predictable and lower leadgen spend compared to past quarters were were exploring creating viable alternatives

---

## Tab 2: BrainLift Coach

### Q4 Summary

BrainLift Coach is a tool that actively coaches users through building excellent BrainLifts — living documents that capture one's journey of becoming expert in a specific topic, structured so that spiky points of view can be traced back to supporting insights and facts. Available at coach.crossover.com.

#### **What it does:**

- **Teaching**: 27 short lessons organized into three mastery tracks, with AI-generated quizzes and progressive unlocking to ensure mastery before advancement
- **Coaching:** Chrome extension delivers live feedback directly in Workflowy as users build, providing guidance at point of creation
- **Building:** Once you link your BrainLift, it becomes a magnet for relevant content — the system knows your purpose and automatically pulls insights and SPOVs from your meetings (via Read.ai) and documents that match what you're trying to learn.
- **Enabling**: MCP integration embeds organizational knowledge into IDEs (Cursor, VSCode), letting engineers for example query "What does my team think about this problem?" and surface relevant SPOVs
- **Institutionalizing**: Automatically creates tasks and follows up when it hears participants say "X should create a BrainLift on Y". Managers can assign and track BrainLift tasks and let the BrainLift coach follow through.
- **Training service**: Ruben runs intensive one-week programs for people who want to build up their BrainLifting skills, with hands-on guidance and feedback.

**Results, in numbers:**

- 68 BrainLifts created, 124 DOK4 SPOVs, 375 DOK3 Insights
- 65 new users (down 55% from Q3), 30 created BrainLifts (44% conversion)
- 299 lessons completed by 45 users, only 1 completed full curriculum (27 lessons)
- 1,727 feedback bubbles opened while users were working on BrainLifts straight into Workflowy
- 86% of BrainLifts had quality Purpose statements (4/5+)
- Total cost: $14,157 ($35/user/month) - activity recognition is 2/3rds of it and its impact is lowest as users are not actually focused on consistently spending time on brainlifts

#### **Key Wins:**

- **Email brainlift assistant improved significantly:**
  - Quality of extracted insights and SPOVs improved - from digging for gems to consistently finding good suggestions each time
  - Coach listens through meetings, picks up asks or plans to create brainlifts and follows through with the assignee, collecting all helpful text
- **Workflowy embedded coach helps -** feedback and suggestions are now embedded in Workflowy. This works much like Grammarly with prioritized action items popping up.
- **Ran one BrainLift Mastery Course:** One-week intensive for 6 people; 80% attendance among active participants
- **MCP shows promise for embedded access** - Early adoption suggests meeting engineers in IDEs solves Workflowy barrier, making it easy to surface up expertise from the IDE/AI environment, run ideas against brainlifts, find experts or apply brainlifts to files in the workspace
- **User research prevented wasted investment** - 100+ interviews surfaced artificial market insight, redirecting from feature optimization to organizational strategy

#### **Key Learnings:**

- **Q4 turned out to be a discovery phase, not a growth phase** - we're solving an organizational alignment problem - the practical applications of brainlifts, not a product problem. Our features work; motivation doesn't exist.
- **Need to be integrated into the team/business plans** - Users won't adopt it organically. Success requires embedding BrainLift planning as part of current workflows:
  - Turn quarter planning into an exercise of planning brainflits the team needs to work on
  - Follow users at work - extract brainlift action items from meetings or conversations
  - Include brainlift training during onboarding
- **Alpha School Collaboration did not work**: Required pedagogically validated curriculum; BLC's credibility gap made independent development by Alpha School easier
- **David Perell Partnership sank**: Value proposition unclear without Trilogy's internal ecosystem, despite initial interest, David did not take any actual actions in the end

#### **Core Challenges**

- **Artificial market:** Top-down mandate removes intrinsic motivation
- **Workflowy dependency:** Half of WsEng engineers don't use it, preferring IDEs/Github
- **Inconsistent understanding:** Teams interpret BrainLift purpose/usage differently; no single source of truth
- **Behavioral problem:** Users don't see BrainLift creation solving their problems

---

### Q1 Plan

The strategy for Q1 is to focus on current customers, narrow scope, and stop spinning wheels on adoption resistance. The direction: Middle path — not killing it, not broad rollout, but focused on the small set of people actually using it. We believe that this smaller but concrete wins with an engaged group is what will then help get the ball rolling across the wider organization.

#### **Tactics**

- **Integrate into Crossover onboarding**: Every new hire gets the course and is as part of onboarding and is invited to attend a 10h program, over the course of one week on how to build brainlifts. We offer it free but won't force it or chase people who don't engage.
  - **Exclude Alpha school-side**: Remote education staff yes, on-site school personnel no.
- **Focus on aligned users**: We have got good feedback from the learning science team and key people in different parts of the org, leaders or ICs. We will
  - 1. Work with them as design partners — listen to their feedback.
  - 2. Grow and nurture the community - share lessons, approaches that work or do not, success stories.
  - 3. Improve based on their input - improve content suggestions, add AI-based research and structured expertise building/learning, help discover experts or aligned/opposing points of view.
- **Work with invested leaders/managers** - help them grow the habit of building brainlifts in their teams starting from the team's main goals and initiatives.
  - **White glove service to leverage BrainLift Coach in their part of the organization** to plan brainlifts to build connected to their goals, assign owners, make constant progress and create high quality brainlifts.
  - **Continue offering intensive one-week programs** for people who want to build up their BrainLifting skills, with hands-on guidance and feedback.

---

## Tab 3: WorkSmart

### Q4 Results

#### **WorkSmart AI Vision:**

- **What it does AI Vision generated activity ontology for enterprises:** it analyzes user activity based on desktop video capture and uses LLM Vision and outputs a detailed qualitative data structure (ontology) focused on what core components of knowledge work - decisions, problems SPOVs, work results, AI usage and results, blockers, collaboration, research, brainlift activity.
- **How to use it**: through AIPIs (MCP)
- **Cost**: ~$320/user/month (~200 users currently enabled)
- **Who uses it**:
  - **SuperBuilders**
    - Brandon: "I think it's awesome. It allowed me to produce detailed reports on the projects people are working on and compare it to their objectives. The level of detail is great. I wanted to build a proper pipeline that produced metrics / reports but I moved off the SB project and handed over to Itamar. It is helpful to manage the 100+ person SB team. I wouldn't pay to use it for my account manager team though, their performance is measured in retention + upsells. I think Joe / DR / Artie would all be disappointed if this got shut down, but I agree it's not being used to its full potential"
  - **Central Eng** (large part of the team)
    - Insights: just like "software observability" is core to any large scale product, "team observability" is critical to innovation, culture alignment and productivity. Jozsef wants to use it as an observability tool for workunits, a mechanism to identify deviations and learn from them. The goal: use it to focus managers on what matters most and makes the most impact.
  - **WSEng, Central TPM**
    - Team management mechanisms are important - WorkSmart AI, connected to JIRA and other systems, tells a clear story of individual progress, work process and innovation. In addition to that, the big opportunity is uncovering hidden decisions that engineers/TPMs make - beyond what is visible in code/specs. It is valuable to capture these decisions, share them with the relevant group, and learn from them.

#### **WorkSmart:**

- Rebuilt and rolled out in beta a new vibe-coded MacOS native tracker
- XO Manage App is way faster: improved average API response time from 20s to <1s
- Simplified time approval workflows - to save hiring manager time
- Turned XOManage into the reference system for active contractors, and improved ITOps data feeds integration to enable them to offer automatic provisioning and access policy enforcement
- Eliminated timecards size limits - fixing upload failures and unlocking 10x screenshots (higher fidelity)
- Migrated to MySQL 8 upgrade, moving off EOL, avoiding EOL AWS support fees

---

### Q1 Plan

The strategy for Q1 is to cover operational costs, encourage adoption, and limit development to small enablement features.

1. **Crossover will sponsor WorkSmart Vision AI** for teams that want to use it. No new major development — focus on removing friction, and letting teams discover value.
2. **Encourage experimentation**: Proactively offer to teams with potential use cases. Let them use MCPs, query the data, and find value.
3. **Small enablement features only**: Open to lightweight automation that facilitates adoption — e.g., scheduled queries that surface insights via email (similar to BrainLift Coach emails), simple interfaces for experimenting with prompts.

**Use-cases:**

- **Jozsef / Central Eng**: Observability for work units — define work units, identify deviations, learn from patterns
- **Colin / Support**: Onboarding and coaching new support engineers in first 2-3 weeks when managers lack time for hands-on coaching
- **Jamie / Ops**: Improve operations across all involved teams during imports - start from the list of people working on the acquisition and what function or workstream they are working in, and then query WorkSmart to say what got done yesterday in each workstream, what appear to be the big open items, and where does it look like people are blocked. This would serve not only for a centralized coordination but would help the entire team surface up knowledge and insights and create visibility across activities.
- **Central TPM / WSEng**: Capture hidden decisions engineers and TPMs make beyond what's visible in code or specs

---

## Tab 4: Budget Breakdown

| _Crossover Pipelines_  |       Budget |     | _Sourcing_           |       Budget |     | _Brand & Reputation_ |       Budget |
| :--------------------- | -----------: | :-- | :------------------- | -----------: | :-- | :------------------- | -----------: |
| Infrastructure costs   |     $279,975 |     | Sourcing - LinkedIn  |     $205,839 |     | Upwork Expert Hire   |      $77,000 |
| PeopleOps Managers     |     $189,025 |     | Upwork Expert Hire   |     $178,750 |     | Marketing team       |      $62,400 |
| WSEng                  |     $187,538 |     | Marketing team       |      $15,600 |     | Video production     |      $50,000 |
| Central Support        |     $160,047 |     | Recruiting materials |       $5,000 |     | Zamstars Outsourcing |      $30,000 |
| Sourcing ops & Support |      $41,600 |     | **Grand Total**      | **$405,189** |     | Brand marketing      |      $20,000 |
| Zamstars Outsourcing   |      $20,000 |     |                      |              |     | Marketing tools      |       $7,062 |
| Upwork Expert Hire     |      $11,000 |     |                      |              |     | **Grand Total**      | **$246,462** |
| **Grand Total**        | **$889,184** |     |                      |              |     |                      |              |

| _Badges & Proctoring_ |       Budget |     | _Core/Other_       |       Budget |
| :-------------------- | -----------: | :-- | :----------------- | -----------: |
| Badges                |      $84,250 |     | Core               |     $700,350 |
| ID/Background checks  |      $24,259 |     | Upwork Expert Hire |       $8,250 |
| **Grand Total**       | **$108,509** |     | **Grand Total**    | **$708,600** |

| _WorkSmart Base_     |       Budget |     | _BL Coach + WS AI_   |       Budget |     | **Product**     | **/user/month** |
| :------------------- | -----------: | :-- | :------------------- | -----------: | :-- | :-------------- | --------------: |
| Central Support      |     $170,493 |     | Infrastructure costs |     $289,323 |     | WorkSmart AI    |            $350 |
| Infrastructure costs |     $147,853 |     | WSEng                |      $81,713 |     | BrainLift Coach |             $10 |
| Central Eng/TPM      |     $118,500 |     | Central Eng/TPM      |      $24,000 |     | WorkSmart Base  |             $37 |
| COO as a service     |      $50,000 |     | **Grand Total**      | **$395,035** |     |                 |                 |
| ID/Background checks |      $26,000 |     |                      |              |     |                 |                 |
| Tools                |      $13,000 |     |                      |              |     |                 |                 |
| **Grand Total**      | **$525,846** |     |                      |              |     |                 |                 |
